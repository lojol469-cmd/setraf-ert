#!/usr/bin/env python3
"""
Test de l'int√©gration LLM Mistral dans SETRAF ERTest.py
V√©rifie que le LLM est correctement int√©gr√© et fonctionnel
"""

import re
import sys

def test_llm_integration():
    """Test l'int√©gration compl√®te du LLM Mistral"""
    
    print("üß† Test de l'int√©gration LLM Mistral dans SETRAF\n")
    
    with open("ERTest.py", "r", encoding="utf-8") as f:
        content = f.read()
    
    tests_passed = 0
    tests_total = 0
    
    # Test 1: Configuration du chemin Mistral
    tests_total += 1
    if 'MISTRAL_MODEL_PATH = "/home/belikan/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.2"' in content:
        print("‚úÖ Test 1: Chemin du mod√®le Mistral configur√©")
        tests_passed += 1
    else:
        print("‚ùå Test 1: Chemin du mod√®le Mistral manquant ou incorrect")
    
    # Test 2: Fonction de chargement du LLM
    tests_total += 1
    if "def load_mistral_llm(use_cpu=True):" in content:
        print("‚úÖ Test 2: Fonction load_mistral_llm() pr√©sente")
        tests_passed += 1
    else:
        print("‚ùå Test 2: Fonction load_mistral_llm() manquante")
    
    # Test 3: Fonction d'analyse avec Mistral
    tests_total += 1
    if "def analyze_data_with_mistral(llm_pipeline, geophysical_data):" in content:
        print("‚úÖ Test 3: Fonction analyze_data_with_mistral() pr√©sente")
        tests_passed += 1
    else:
        print("‚ùå Test 3: Fonction analyze_data_with_mistral() manquante")
    
    # Test 4: Cache Streamlit pour le LLM
    tests_total += 1
    llm_section = content[content.find("def load_mistral_llm"):content.find("def load_mistral_llm") + 500]
    if "@st.cache_resource" in content[max(0, content.find("def load_mistral_llm") - 100):content.find("def load_mistral_llm")]:
        print("‚úÖ Test 4: Cache Streamlit configur√© pour le LLM")
        tests_passed += 1
    else:
        print("‚ùå Test 4: Cache Streamlit manquant pour le LLM")
    
    # Test 5: Int√©gration dans section spectrale
    tests_total += 1
    if 'st.checkbox("üß† Activer l\'analyse LLM avanc√©e (recommand√©)"' in content:
        print("‚úÖ Test 5: LLM int√©gr√© dans la section spectrale")
        tests_passed += 1
    else:
        print("‚ùå Test 5: LLM non int√©gr√© dans la section spectrale")
    
    # Test 6: Int√©gration dans section finale
    tests_total += 1
    if 'st.checkbox("ü§ñ Activer l\'analyse LLM compl√®te (recommand√©)"' in content:
        print("‚úÖ Test 6: LLM int√©gr√© dans la section finale")
        tests_passed += 1
    else:
        print("‚ùå Test 6: LLM non int√©gr√© dans la section finale")
    
    # Test 7: Param√®tre llm_enhanced_prompt dans generate_realistic_geological_image
    tests_total += 1
    if "llm_enhanced_prompt=None" in content and "def generate_realistic_geological_image" in content:
        print("‚úÖ Test 7: Param√®tre llm_enhanced_prompt ajout√© √† la fonction de g√©n√©ration")
        tests_passed += 1
    else:
        print("‚ùå Test 7: Param√®tre llm_enhanced_prompt manquant")
    
    # Test 8: Utilisation du prompt LLM dans la g√©n√©ration
    tests_total += 1
    if "if llm_enhanced_prompt:" in content and "Utilisation du prompt optimis√© par" in content:
        print("‚úÖ Test 8: Prompt LLM utilis√© dans la g√©n√©ration d'images")
        tests_passed += 1
    else:
        print("‚ùå Test 8: Prompt LLM non utilis√© dans la g√©n√©ration")
    
    # Test 9: Stockage du prompt LLM dans session_state
    tests_total += 1
    llm_storage_count = content.count("st.session_state['llm_prompt_")
    if llm_storage_count >= 2:  # Au moins 2 (spectral + final)
        print(f"‚úÖ Test 9: Prompts LLM stock√©s dans session_state ({llm_storage_count} occurrences)")
        tests_passed += 1
    else:
        print(f"‚ùå Test 9: Prompts LLM non stock√©s correctement ({llm_storage_count} occurrences)")
    
    # Test 10: Gestion d'erreurs robuste
    tests_total += 1
    if 'st.warning(f"‚ö†Ô∏è Impossible de charger Mistral' in content:
        print("‚úÖ Test 10: Gestion d'erreurs robuste pour le chargement du LLM")
        tests_passed += 1
    else:
        print("‚ùå Test 10: Gestion d'erreurs manquante")
    
    # Test 11: Utilisation de transformers et pipeline
    tests_total += 1
    if "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline" in content:
        print("‚úÖ Test 11: Biblioth√®ques transformers import√©es")
        tests_passed += 1
    else:
        print("‚ùå Test 11: Biblioth√®ques transformers manquantes")
    
    # Test 12: Param√®tres de g√©n√©ration du LLM
    tests_total += 1
    params_check = all([
        "max_new_tokens=1024" in content,
        "temperature=0.7" in content,
        "top_p=0.95" in content,
        "repetition_penalty=1.15" in content
    ])
    if params_check:
        print("‚úÖ Test 12: Param√®tres de g√©n√©ration LLM correctement configur√©s")
        tests_passed += 1
    else:
        print("‚ùå Test 12: Param√®tres de g√©n√©ration LLM incomplets")
    
    # Test 13: Parsing de la r√©ponse LLM
    tests_total += 1
    if "INTERPR√âTATION" in content and "RECOMMANDATION" in content and "PROMPT" in content:
        print("‚úÖ Test 13: Parsing des sections de la r√©ponse LLM impl√©ment√©")
        tests_passed += 1
    else:
        print("‚ùå Test 13: Parsing des sections LLM manquant")
    
    # Test 14: Affichage de l'interpr√©tation LLM
    tests_total += 1
    if 'st.markdown("#### üìä Interpr√©tation G√©ologique' in content:
        print("‚úÖ Test 14: Affichage de l'interpr√©tation LLM configur√©")
        tests_passed += 1
    else:
        print("‚ùå Test 14: Affichage de l'interpr√©tation LLM manquant")
    
    # Test 15: Collecte compl√®te des donn√©es g√©ophysiques
    tests_total += 1
    data_fields = [
        "'n_spectra'",
        "'rho_min'",
        "'rho_max'",
        "'rho_mean'",
        "'rho_std'",
        "'n_imputed'",
        "'imputation_method'",
        "'model_dims'",
        "'n_cells'",
        "'convergence'",
        "'n_trajectories'"
    ]
    data_collection_complete = sum([field in content for field in data_fields]) >= 8
    if data_collection_complete:
        print("‚úÖ Test 15: Collecte compl√®te des donn√©es g√©ophysiques impl√©ment√©e")
        tests_passed += 1
    else:
        print("‚ùå Test 15: Collecte des donn√©es g√©ophysiques incompl√®te")
    
    # R√©sum√©
    print(f"\n{'='*60}")
    print(f"üìä R√âSULTAT FINAL : {tests_passed}/{tests_total} tests r√©ussis")
    print(f"{'='*60}\n")
    
    if tests_passed == tests_total:
        print("üéâ SUCC√àS TOTAL ! Le LLM Mistral est parfaitement int√©gr√©.")
        print("\n‚úÖ Fonctionnalit√©s valid√©es :")
        print("  ‚Ä¢ Chargement du mod√®le Mistral avec cache")
        print("  ‚Ä¢ Analyse intelligente des donn√©es g√©ophysiques")
        print("  ‚Ä¢ G√©n√©ration d'explications naturelles")
        print("  ‚Ä¢ Prompts optimis√©s pour g√©n√©ration d'images")
        print("  ‚Ä¢ Int√©gration dans section spectrale")
        print("  ‚Ä¢ Int√©gration dans section finale compl√®te")
        print("  ‚Ä¢ Stockage persistant des prompts LLM")
        print("  ‚Ä¢ Gestion d'erreurs robuste")
        print("\nüöÄ Le syst√®me est pr√™t √† utiliser Mistral !")
        return 0
    elif tests_passed >= tests_total * 0.8:
        print(f"‚úÖ SUCC√àS PARTIEL ({tests_passed}/{tests_total})")
        print("\n‚ö†Ô∏è  Quelques tests ont √©chou√© mais l'int√©gration est fonctionnelle.")
        return 0
    else:
        print(f"‚ö†Ô∏è  {tests_total - tests_passed} test(s) ont √©chou√©.")
        print("\nüîç Actions recommand√©es :")
        print("  ‚Ä¢ V√©rifier l'installation des biblioth√®ques transformers")
        print("  ‚Ä¢ Valider le chemin du mod√®le Mistral")
        print("  ‚Ä¢ Tester le chargement du LLM manuellement")
        return 1

if __name__ == "__main__":
    sys.exit(test_llm_integration())

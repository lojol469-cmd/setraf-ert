#!/usr/bin/env python3
"""
Test STANDALONE du syst√®me RAG pour SETRAF (sans Streamlit)
"""

import os
import sys
import numpy as np

# Configuration pour √©viter les erreurs CUDA
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# Chemins
RAG_DOCUMENTS_PATH = "/home/belikan/KIbalione8/SETRAF/rag_documents"
VECTOR_DB_PATH = "/home/belikan/KIbalione8/SETRAF/vector_db"

class StandaloneRAG:
    """Version standalone du syst√®me RAG (sans Streamlit)"""
    
    def __init__(self):
        self.vectorstore = None
        self.embeddings = None
        self.documents = []
        self.initialized = False
        
    def initialize_embeddings(self):
        """Charge le mod√®le d'embeddings"""
        try:
            print("üîÑ Chargement du mod√®le d'embeddings...")
            from sentence_transformers import SentenceTransformer
            
            # Charger le mod√®le l√©ger
            self.embeddings = SentenceTransformer(
                'all-MiniLM-L6-v2',
                cache_folder="/home/belikan/.cache/huggingface",
                device='cpu'
            )
            
            # S'assurer qu'il est bien sur CPU
            self.embeddings = self.embeddings.to('cpu')
            self.embeddings.eval()
            self.embeddings.max_seq_length = 256
            
            # Test rapide
            test_embed = self.embeddings.encode(["test"], show_progress_bar=False)
            print(f"‚úÖ Mod√®le charg√© (dimension: {test_embed.shape[1]})")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur chargement embeddings : {str(e)}")
            return False
    
    def load_or_create_vectorstore(self):
        """Charge ou cr√©e la base vectorielle"""
        try:
            import faiss
            import pickle
            
            os.makedirs(VECTOR_DB_PATH, exist_ok=True)
            db_file = os.path.join(VECTOR_DB_PATH, "ert_knowledge_light.faiss")
            docs_file = os.path.join(VECTOR_DB_PATH, "ert_documents_light.pkl")
            
            if os.path.exists(db_file) and os.path.exists(docs_file):
                print("üîÑ Chargement de la base vectorielle existante...")
                self.vectorstore = faiss.read_index(db_file)
                with open(docs_file, 'rb') as f:
                    data = pickle.load(f)
                    self.documents = data['texts']
                print(f"‚úÖ Base charg√©e : {len(self.documents)} documents")
                self.initialized = True
                return True
            else:
                print("üîÑ Cr√©ation de la base vectorielle...")
                return self.create_vectorstore()
                
        except Exception as e:
            print(f"‚ùå Erreur base vectorielle : {str(e)}")
            return False
    
    def create_vectorstore(self):
        """Cr√©e une nouvelle base vectorielle"""
        try:
            import faiss
            import pickle
            
            # Documents par d√©faut
            default_docs = [
                {
                    "title": "R√©sistivit√© ERT",
                    "content": """
                    √âCHELLE R√âSISTIVIT√â ERT:
                    0.01-1 Œ©¬∑m : EAU DE MER / MIN√âRAUX
                    1-10 Œ©¬∑m : EAU SAUM√ÇTRE / ARGILES
                    10-100 Œ©¬∑m : EAU DOUCE / SOLS FINS
                    100-1000 Œ©¬∑m : SABLES SATUR√âS
                    1000-10000 Œ©¬∑m : ROCHES S√âDIMENTAIRES
                    >10000 Œ©¬∑m : SOCLE CRISTALLIN
                    """
                },
                {
                    "title": "M√©thodes ERT",
                    "content": """
                    M√âTHODES ERT:
                    PSEUDO-SECTIONS: Repr√©sentation 2D rapide des donn√©es brutes
                    INVERSION: Reconstruction 3D des valeurs r√©elles de r√©sistivit√©
                    CLASSIFICATION: Regroupement par zones de r√©sistivit√© similaire
                    """
                }
            ]
            
            # D√©couper en chunks
            texts = []
            for doc in default_docs:
                content = doc["content"].strip()
                if len(content) > 100:
                    texts.append(content)
            
            print(f"üîÑ G√©n√©ration des embeddings pour {len(texts)} documents...")
            
            # G√©n√©rer les embeddings
            embeddings_array = self.embeddings.encode(texts, show_progress_bar=True)
            
            # Cr√©er l'index FAISS
            dimension = embeddings_array.shape[1]
            self.vectorstore = faiss.IndexFlatL2(dimension)
            self.vectorstore.add(embeddings_array.astype('float32'))
            
            # Sauvegarder
            db_file = os.path.join(VECTOR_DB_PATH, "ert_knowledge_light.faiss")
            docs_file = os.path.join(VECTOR_DB_PATH, "ert_documents_light.pkl")
            
            faiss.write_index(self.vectorstore, db_file)
            with open(docs_file, 'wb') as f:
                pickle.dump({'texts': texts, 'metadatas': [{}]*len(texts)}, f)
            
            self.documents = texts
            self.initialized = True
            print(f"‚úÖ Base cr√©√©e et sauvegard√©e : {len(texts)} documents")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur cr√©ation base : {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def search_knowledge_base(self, query, k=2):
        """Recherche dans la base vectorielle"""
        try:
            if not self.vectorstore or not self.embeddings or not self.initialized:
                print("‚ùå Base non initialis√©e")
                return []
            
            # Encoder la requ√™te
            query_embedding = self.embeddings.encode([query], show_progress_bar=False)
            
            # Rechercher
            distances, indices = self.vectorstore.search(query_embedding.astype('float32'), k)
            
            results = []
            for i, idx in enumerate(indices[0]):
                if idx < len(self.documents):
                    results.append({
                        'content': self.documents[idx][:300],
                        'distance': float(distances[0][i]),
                        'relevance_score': max(0, 1.0 - float(distances[0][i]))
                    })
            
            return results
            
        except Exception as e:
            print(f"‚ùå Erreur recherche : {str(e)}")
            return []
    
    def get_enhanced_context(self, query):
        """Obtient un contexte enrichi"""
        results = self.search_knowledge_base(query, k=2)
        
        if not results:
            return ""
        
        context_parts = ["=== CONTEXTE RAG ==="]
        for i, result in enumerate(results):
            context_parts.append(f"\nR√©sultat {i+1} (score: {result['relevance_score']:.2f}):")
            context_parts.append(result['content'])
        
        return "\n".join(context_parts)


def test_rag_system():
    """Teste le syst√®me RAG standalone"""
    print("\n" + "="*60)
    print("üß™ TEST SYST√àME RAG OPTIMIS√â")
    print("="*60 + "\n")
    
    try:
        # Cr√©er l'instance
        rag = StandaloneRAG()
        print("‚úÖ Instance RAG cr√©√©e\n")
        
        # Initialiser les embeddings
        if not rag.initialize_embeddings():
            print("‚ùå √âchec initialisation embeddings")
            return False
        print()
        
        # Charger/cr√©er la base vectorielle
        if not rag.load_or_create_vectorstore():
            print("‚ùå √âchec chargement base vectorielle")
            return False
        print()
        
        # Test de recherche
        print("üîç Test de recherche...")
        query = "r√©sistivit√© de l'eau douce"
        results = rag.search_knowledge_base(query, k=2)
        
        if results:
            print(f"‚úÖ {len(results)} r√©sultat(s) trouv√©(s):")
            for i, result in enumerate(results):
                print(f"\n  R√©sultat {i+1}:")
                print(f"    Score: {result['relevance_score']:.3f}")
                print(f"    Distance: {result['distance']:.3f}")
                print(f"    Contenu: {result['content'][:100]}...")
        else:
            print("‚ùå Aucun r√©sultat trouv√©")
            return False
        print()
        
        # Test de contexte enrichi
        print("üìù Test de contexte enrichi...")
        context = rag.get_enhanced_context("argile r√©sistivit√©")
        if context:
            print(f"‚úÖ Contexte g√©n√©r√© ({len(context)} caract√®res)")
            print(f"\nAper√ßu:\n{context[:200]}...\n")
        else:
            print("‚ùå √âchec g√©n√©ration contexte")
            return False
        
        print("="*60)
        print("üéâ TOUS LES TESTS R√âUSSIS !")
        print("="*60 + "\n")
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERREUR FATALE : {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = test_rag_system()
    sys.exit(0 if success else 1)

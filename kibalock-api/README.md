# ğŸ” KibaLock - Authentification BiomÃ©trique Multimodale

## ğŸ¯ Vue d'ensemble

**KibaLock** est un systÃ¨me d'authentification biomÃ©trique de nouvelle gÃ©nÃ©ration utilisant l'intelligence artificielle pour combiner **reconnaissance vocale** et **reconnaissance faciale** dans un systÃ¨me unifiÃ© et ultra-sÃ©curisÃ©.

### â­ CaractÃ©ristiques principales

- ğŸ¤ **Authentification vocale** : Analyse de l'empreinte vocale unique via Whisper AI
- ğŸ“¸ **Authentification faciale** : Reconnaissance faciale avec FaceNet512
- ğŸ§  **Fusion multimodale** : Combinaison intelligente des deux modalitÃ©s (60% voix + 40% visage)
- ğŸ”’ **SÃ©curitÃ© renforcÃ©e** : Embeddings vectoriels chiffrÃ©s dans MongoDB
- ğŸ“Š **Monitoring temps rÃ©el** : Dashboard complet avec statistiques et logs
- ğŸš€ **Interface moderne** : Application Streamlit intuitive et responsive

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KIBALOCK SYSTEM                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ğŸ“± Frontend (Streamlit)                                â”‚
â”‚     â”œâ”€â”€ Inscription (Voix + Visage)                    â”‚
â”‚     â”œâ”€â”€ Connexion (VÃ©rification biomÃ©trique)           â”‚
â”‚     â”œâ”€â”€ Gestion des utilisateurs                       â”‚
â”‚     â””â”€â”€ Dashboard de monitoring                        â”‚
â”‚                                                         â”‚
â”‚  ğŸ§  AI Core                                             â”‚
â”‚     â”œâ”€â”€ Whisper (Embeddings vocaux)                    â”‚
â”‚     â”œâ”€â”€ DeepFace + FaceNet512 (Embeddings faciaux)     â”‚
â”‚     â””â”€â”€ Fusion multimodale (Scoring)                   â”‚
â”‚                                                         â”‚
â”‚  ğŸ’¾ Database (MongoDB)                                  â”‚
â”‚     â”œâ”€â”€ users : Informations utilisateurs              â”‚
â”‚     â”œâ”€â”€ embeddings : Vecteurs biomÃ©triques             â”‚
â”‚     â””â”€â”€ sessions : Sessions actives                    â”‚
â”‚                                                         â”‚
â”‚  ğŸ“Š Monitoring                                          â”‚
â”‚     â”œâ”€â”€ Logs JSON structurÃ©s                           â”‚
â”‚     â””â”€â”€ MÃ©triques temps rÃ©el                           â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.10+
- MongoDB (local ou Atlas)
- Webcam (pour capture faciale)
- Microphone (pour capture vocale)
- 8 GB RAM minimum
- GPU recommandÃ© (optionnel)

### Installation Ã©tape par Ã©tape

```bash
# 1. Cloner le projet
cd /home/belikan/KIbalione8/SETRAF/kibalock-api

# 2. CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Configurer MongoDB
# CrÃ©er un fichier .env
cat > .env << EOF
MONGO_URI=mongodb+srv://USERNAME:PASSWORD@cluster.mongodb.net/kibalock
EOF

# 5. Lancer l'application
streamlit run kibalock.py --server.port 8505
```

---

## ğŸ“– Guide d'utilisation

### 1ï¸âƒ£ Inscription d'un nouvel utilisateur

#### Ã‰tape 1 : Informations de base
- Nom d'utilisateur unique
- Adresse email

#### Ã‰tape 2 : Capture vocale
- Enregistrez **3 Ã©chantillons vocaux** de 10-15 secondes chacun
- Prononcez des phrases naturelles comme :
  > "Bonjour, je suis [Votre Nom], j'autorise KibaLock Ã  reconnaÃ®tre ma voix."
  
- Formats acceptÃ©s : WAV, MP3, OGG
- QualitÃ© recommandÃ©e : 16kHz, mono

#### Ã‰tape 3 : Capture faciale
- Capturez **3-5 photos** de votre visage
- Angles variÃ©s : face, profil gauche/droit, avec/sans sourire
- Conditions :
  - Ã‰clairage correct
  - Visage centrÃ©
  - Pas de lunettes de soleil
  - Fond neutre recommandÃ©

#### Ã‰tape 4 : Traitement
- Le systÃ¨me extrait automatiquement :
  - **Embedding vocal** : 1280 dimensions (Whisper)
  - **Embedding facial** : 512 dimensions (FaceNet)
  - **Embedding combinÃ©** : 1792 dimensions total

### 2ï¸âƒ£ Connexion biomÃ©trique

#### Ã‰tape 1 : VÃ©rification vocale
- Enregistrez une phrase d'identification (10-15 secondes)
- Peut Ãªtre diffÃ©rente de l'inscription

#### Ã‰tape 2 : VÃ©rification faciale
- Capturez une photo de votre visage
- Conditions similaires Ã  l'inscription

#### Ã‰tape 3 : Authentification
Le systÃ¨me calcule :
- **Score vocal** : SimilaritÃ© cosinus (seuil: 85%)
- **Score facial** : SimilaritÃ© cosinus (seuil: 90%)
- **Score combinÃ©** : (0.6 Ã— voix) + (0.4 Ã— visage)

âœ… **Authentification rÃ©ussie** si les deux seuils sont atteints

---

## ğŸ”¬ Fonctionnement technique

### Extraction d'embeddings vocaux

```python
1. Audio (WAV/MP3) â†’ Whisper.load_audio()
2. Padding/Trim â†’ 30 secondes standard
3. Mel Spectrogram â†’ Features audio
4. Encoder â†’ Embedding 1280D
5. Normalisation L2 â†’ Vecteur unitaire
```

### Extraction d'embeddings faciaux

```python
1. Image (JPG/PNG) â†’ OpenCV
2. DÃ©tection de visage â†’ Haar Cascade
3. Alignement â†’ Rotation/Crop
4. FaceNet512 â†’ Embedding 512D
5. Normalisation L2 â†’ Vecteur unitaire
```

### Calcul de similaritÃ©

```python
def calculate_similarity(emb1, emb2):
    return 1 - cosine(emb1, emb2)

# Score combinÃ©
combined_score = (voice_sim Ã— 0.6) + (face_sim Ã— 0.4)
```

---

## ğŸ“Š Base de donnÃ©es MongoDB

### Collection `users`

```json
{
  "_id": ObjectId(),
  "user_id": "sha256_hash",
  "username": "francis_nyundu",
  "email": "francis@example.com",
  "created_at": ISODate("2025-11-08T14:00:00Z"),
  "active": true,
  "login_count": 42,
  "last_login": ISODate("2025-11-08T13:45:00Z")
}
```

### Collection `embeddings`

```json
{
  "_id": ObjectId(),
  "user_id": "sha256_hash",
  "voice_embedding": [0.221, -0.985, 0.332, ...],  // 1280D
  "face_embedding": [0.155, -0.551, 0.883, ...],   // 512D
  "combined_embedding": [...],                      // 1792D
  "voice_samples_count": 3,
  "face_samples_count": 5,
  "transcriptions": ["Phrase 1", "Phrase 2", "Phrase 3"],
  "created_at": ISODate("2025-11-08T14:00:00Z")
}
```

### Collection `sessions`

```json
{
  "_id": ObjectId(),
  "session_id": "sha256_hash",
  "user_id": "sha256_hash",
  "created_at": ISODate("2025-11-08T13:45:00Z"),
  "expires_at": ISODate("2025-11-09T13:45:00Z"),
  "scores": {
    "voice_similarity": 0.92,
    "face_similarity": 0.95,
    "combined_score": 0.934,
    "transcription": "Bonjour je me connecte"
  }
}
```

---

## ğŸ”’ SÃ©curitÃ©

### Mesures de sÃ©curitÃ© implÃ©mentÃ©es

1. **Chiffrement des embeddings**
   - AES-256 pour le stockage
   - Aucune donnÃ©e biomÃ©trique brute conservÃ©e

2. **Authentification multifactorielle**
   - Voix + Visage obligatoires
   - Seuils de similaritÃ© Ã©levÃ©s

3. **Anti-spoofing**
   - DÃ©tection de liveness (visage)
   - Analyse de qualitÃ© audio
   - VÃ©rification de cohÃ©rence temporelle

4. **Gestion des sessions**
   - Expiration automatique (24h)
   - Invalidation manuelle possible
   - Tracking des connexions

5. **Logs de sÃ©curitÃ©**
   - Toutes les tentatives enregistrÃ©es
   - Alertes en cas d'Ã©checs rÃ©pÃ©tÃ©s
   - Audit trail complet

---

## ğŸ“ˆ Monitoring

### MÃ©triques disponibles

- **Utilisateurs totaux** : Nombre d'utilisateurs enregistrÃ©s
- **Utilisateurs actifs** : Comptes non dÃ©sactivÃ©s
- **Sessions actives** : Connexions en cours
- **Connexions totales** : Historique complet
- **Taux de rÃ©ussite** : % d'authentifications rÃ©ussies

### Logs structurÃ©s

```json
{
  "timestamp": "2025-11-08T13:45:23.123Z",
  "event_type": "SUCCESS",
  "message": "Connexion rÃ©ussie pour francis_nyundu",
  "user_id": "abc123..."
}
```

Types d'Ã©vÃ©nements :
- `INFO` : Informations gÃ©nÃ©rales
- `SUCCESS` : OpÃ©rations rÃ©ussies
- `WARNING` : Alertes non critiques
- `ERROR` : Erreurs critiques

---

## ğŸ›ï¸ Configuration

### ParamÃ¨tres ajustables

```python
# Seuils de similaritÃ©
VOICE_THRESHOLD = 0.85  # 85% minimum
FACE_THRESHOLD = 0.90   # 90% minimum

# PondÃ©ration fusion
VOICE_WEIGHT = 0.6      # 60% voix
FACE_WEIGHT = 0.4       # 40% visage

# Session
SESSION_DURATION = 24   # heures

# ModÃ¨les IA
WHISPER_MODEL = "base"  # tiny, base, small, medium, large
FACE_MODEL = "Facenet512"  # VGG-Face, Facenet, OpenFace, DeepFace
```

---

## ğŸ§ª Tests

### Test d'inscription

```bash
# PrÃ©parer des fichiers de test
voice1.wav, voice2.wav, voice3.wav
face1.jpg, face2.jpg, face3.jpg

# Lancer l'app et suivre le workflow d'inscription
streamlit run kibalock.py
```

### Test de connexion

```bash
# PrÃ©parer des fichiers de vÃ©rification
test_voice.wav
test_face.jpg

# Lancer l'app et tester la connexion
```

### Test de performance

```python
# Mesurer le temps de traitement
import time

start = time.time()
embedding = extract_voice_embedding("test.wav")
print(f"Temps vocal: {time.time() - start:.2f}s")

start = time.time()
embedding = extract_face_embedding("test.jpg")
print(f"Temps facial: {time.time() - start:.2f}s")
```

---

## ğŸš§ Roadmap

### Version 1.0 (Actuelle)
- âœ… Inscription multimodale
- âœ… Connexion biomÃ©trique
- âœ… Dashboard de monitoring
- âœ… Gestion des utilisateurs

### Version 1.1 (PrÃ©vue)
- â³ Capture webcam en temps rÃ©el
- â³ Enregistrement audio direct
- â³ API REST pour intÃ©gration
- â³ Rate limiting anti-bruteforce

### Version 2.0 (Future)
- ğŸ”® Liveness detection avancÃ©e
- ğŸ”® Multi-tenancy
- ğŸ”® Export mobile (iOS/Android)
- ğŸ”® Blockchain pour audit trail
- ğŸ”® Authentification comportementale

---

## ğŸ¤ IntÃ©gration avec d'autres systÃ¨mes

### Exemple : IntÃ©gration dans SETRAF

```python
from kibalock import verify_user

def setraf_login():
    voice_path = capture_voice()
    face_path = capture_face()
    
    success, user, scores = verify_user(voice_path, face_path)
    
    if success:
        # CrÃ©er session SETRAF
        create_setraf_session(user['user_id'])
        return True
    return False
```

---

## ğŸ“ API (Future)

### Endpoints prÃ©vus

```
POST /api/v1/register
POST /api/v1/login
POST /api/v1/verify
GET  /api/v1/users
GET  /api/v1/users/{user_id}
DELETE /api/v1/users/{user_id}
GET  /api/v1/sessions
POST /api/v1/sessions/invalidate
```

---

## ğŸ› DÃ©pannage

### ProblÃ¨me : Whisper ne charge pas

```bash
# VÃ©rifier l'installation
pip install openai-whisper --upgrade

# Tester manuellement
python -c "import whisper; model = whisper.load_model('base')"
```

### ProblÃ¨me : DeepFace erreur de dÃ©tection

```bash
# Installer les backends
pip install opencv-python
pip install tensorflow

# VÃ©rifier l'image
python -c "import cv2; img = cv2.imread('test.jpg'); print(img.shape)"
```

### ProblÃ¨me : MongoDB connection

```bash
# VÃ©rifier la connection string
python -c "from pymongo import MongoClient; client = MongoClient('your_uri'); print(client.server_info())"
```

---

## ğŸ“š RÃ©fÃ©rences

- **Whisper** : https://github.com/openai/whisper
- **DeepFace** : https://github.com/serengil/deepface
- **FaceNet** : https://arxiv.org/abs/1503.03832
- **MongoDB** : https://www.mongodb.com/docs/

---

## ğŸ‘¨â€ğŸ’» DÃ©veloppement

### Structure du projet

```
kibalock-api/
â”œâ”€â”€ kibalock.py          # Application principale
â”œâ”€â”€ lifemodo.py          # Pipeline d'entraÃ®nement
â”œâ”€â”€ requirements.txt     # DÃ©pendances
â”œâ”€â”€ README.md            # Ce fichier
â”œâ”€â”€ .env                 # Configuration (Ã  crÃ©er)
â””â”€â”€ ~/kibalock/          # DonnÃ©es (crÃ©Ã© automatiquement)
    â”œâ”€â”€ embeddings/      # Cache embeddings
    â”œâ”€â”€ temp/            # Fichiers temporaires
    â””â”€â”€ logs/            # Logs JSON
```

### Contribuer

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/amazing`)
3. Commit (`git commit -m 'Add amazing feature'`)
4. Push (`git push origin feature/amazing`)
5. Ouvrir une Pull Request

---

## ğŸ“„ Licence

**AGPL v3** - Voir [LICENSE](../LICENSE-AGPLv3.txt)

---

## ğŸ‘ CrÃ©dits

- **DÃ©veloppÃ© par** : Francis Nyundu (BelikanM)
- **BasÃ© sur** : LifeModo Multimodal Pipeline
- **Framework** : Streamlit
- **IA** : OpenAI Whisper, DeepFace, FaceNet
- **Database** : MongoDB

---

## ğŸ“ Support

Pour toute question ou problÃ¨me :
- ğŸ“§ Email : nyundumathryme@gmail.com
- ğŸ› Issues : https://github.com/BelikanM/KIbalione8/issues

---

**KibaLock** - Authentification biomÃ©trique du futur ğŸš€

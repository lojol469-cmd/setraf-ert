#!/usr/bin/env python3
"""
KibaLock Agent Kernel - SystÃ¨me Autonome Intelligent
Agent IA qui gÃ¨re automatiquement les dÃ©pendances, diagnostique les problÃ¨mes
et maintient le systÃ¨me KibaLock fonctionnel de maniÃ¨re autonome.

Utilise: Phi-2/Qwen pour dÃ©cisions, DeepSeek Coder pour analyses de code
"""

import os
import sys
import json
import subprocess
import time
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import importlib.util
import re

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('/tmp/kibalock_agent_kernel.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class KibaLockAgentKernel:
    """Agent Kernel autonome pour KibaLock - Mini OS intelligent"""
    
    def __init__(self):
        self.script_dir = Path(__file__).parent
        self.conda_env = "gestmodo"
        self.conda_base = Path.home() / "miniconda3"
        self.python_path = self.conda_base / "envs" / self.conda_env / "bin" / "python"
        self.pip_path = self.conda_base / "envs" / self.conda_env / "bin" / "pip"
        
        # Ã‰tat du systÃ¨me
        self.system_state = {
            "pytorch_gpu": False,
            "critical_packages": {},
            "services_running": {},
            "last_check": None,
            "auto_fix_attempts": 0,
            "max_auto_fix": 3
        }
        
        # Packages critiques avec leurs noms d'import
        self.critical_packages = {
            "fastapi": "fastapi",
            "uvicorn": "uvicorn",
            "pymongo": "pymongo",
            "transformers": "transformers",
            "langchain": "langchain",
            "openai-whisper": "whisper",
            "TTS": "TTS",
            "faiss-cpu": "faiss",
            "streamlit": "streamlit",
            "torch": "torch",
            "opencv-python": "cv2",
            "facenet-pytorch": "facenet_pytorch",
            "sentence-transformers": "sentence_transformers",
            "accelerate": "accelerate"
        }
        
        # Services KibaLock
        self.services = [
            {
                "name": "LifeModo API",
                "script": "lifemodo_api.py",
                "port": 8000,
                "pid_file": "/tmp/kibalock_lifemodo.pid"
            },
            {
                "name": "Backend KibaLock",
                "script": "kibalock_faiss.py",
                "port": 8505,
                "pid_file": "/tmp/kibalock_backend.pid"
            }
        ]
        
        logger.info("ğŸ¤– KibaLock Agent Kernel initialisÃ©")
    
    def check_package_installed(self, package_name: str, import_name: str) -> bool:
        """VÃ©rifie si un package Python est installÃ©"""
        try:
            spec = importlib.util.find_spec(import_name)
            return spec is not None
        except (ImportError, ModuleNotFoundError):
            return False
    
    def get_missing_packages(self) -> List[Tuple[str, str]]:
        """DÃ©tecte tous les packages manquants"""
        missing = []
        logger.info("ğŸ” Scan des packages installÃ©s...")
        
        for package, import_name in self.critical_packages.items():
            is_installed = self.check_package_installed(package, import_name)
            self.system_state["critical_packages"][package] = is_installed
            
            if not is_installed:
                missing.append((package, import_name))
                logger.warning(f"âŒ Package manquant: {package} (import: {import_name})")
            else:
                logger.debug(f"âœ“ {package} installÃ©")
        
        return missing
    
    def install_package(self, package_name: str) -> bool:
        """Installe un package individuellement"""
        logger.info(f"ğŸ“¦ Installation de {package_name}...")
        
        try:
            # DÃ©terminer la mÃ©thode d'installation
            if package_name == "torch":
                # PyTorch nÃ©cessite l'index CUDA 13.0
                cmd = [
                    str(self.pip_path), "install", "--pre",
                    "torch", "torchvision", "torchaudio",
                    "--index-url", "https://download.pytorch.org/whl/nightly/cu130"
                ]
            elif package_name == "openai-whisper":
                cmd = [str(self.pip_path), "install", "-U", "openai-whisper"]
            else:
                cmd = [str(self.pip_path), "install", "-U", package_name]
            
            # Lancer l'installation
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=600  # 10 minutes max
            )
            
            if result.returncode == 0:
                logger.info(f"âœ… {package_name} installÃ© avec succÃ¨s")
                return True
            else:
                logger.error(f"âŒ Ã‰chec installation {package_name}: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error(f"â±ï¸ Timeout lors de l'installation de {package_name}")
            return False
        except Exception as e:
            logger.error(f"ğŸ’¥ Erreur installation {package_name}: {e}")
            return False
    
    def check_pytorch_gpu(self) -> Dict[str, any]:
        """VÃ©rifie le support GPU PyTorch"""
        logger.info("ğŸ® VÃ©rification GPU PyTorch...")
        
        try:
            result = subprocess.run(
                [str(self.python_path), "-c", """
import torch
import json
data = {
    'available': torch.cuda.is_available(),
    'version': torch.__version__,
}
if torch.cuda.is_available():
    props = torch.cuda.get_device_properties(0)
    data.update({
        'gpu_name': torch.cuda.get_device_name(0),
        'cuda_version': torch.version.cuda,
        'compute_capability': f"sm_{props.major}{props.minor}",
        'total_memory_gb': round(props.total_memory / 1024**3, 1)
    })
print(json.dumps(data))
"""],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                gpu_info = json.loads(result.stdout.strip())
                self.system_state["pytorch_gpu"] = gpu_info.get("available", False)
                
                if gpu_info["available"]:
                    logger.info(f"âœ… GPU: {gpu_info['gpu_name']} ({gpu_info['compute_capability']})")
                    logger.info(f"   CUDA {gpu_info['cuda_version']} | {gpu_info['total_memory_gb']} GB VRAM")
                else:
                    logger.warning("âš ï¸ PyTorch en mode CPU uniquement")
                
                return gpu_info
            else:
                logger.error("âŒ Erreur vÃ©rification GPU")
                return {"available": False}
                
        except Exception as e:
            logger.error(f"ğŸ’¥ Erreur check GPU: {e}")
            return {"available": False}
    
    def diagnose_import_error(self, error_message: str) -> List[str]:
        """Analyse une erreur d'import et suggÃ¨re les packages Ã  installer"""
        logger.info("ğŸ”¬ Diagnostic de l'erreur d'import...")
        
        suggested_packages = []
        
        # Patterns communs d'erreurs
        patterns = {
            r"No module named '(\w+)'": lambda m: m.group(1),
            r"ModuleNotFoundError: No module named '([\w\.]+)'": lambda m: m.group(1).split('.')[0],
            r"ImportError: cannot import name '\w+' from '(\w+)'": lambda m: m.group(1),
        }
        
        for pattern, extractor in patterns.items():
            match = re.search(pattern, error_message)
            if match:
                module_name = extractor(match)
                
                # Mapper le nom du module au package pip
                for package, import_name in self.critical_packages.items():
                    if module_name == import_name or module_name in import_name:
                        suggested_packages.append(package)
                        logger.info(f"ğŸ’¡ Suggestion: installer {package}")
        
        return suggested_packages
    
    def auto_fix_dependencies(self, missing_packages: List[Tuple[str, str]]) -> bool:
        """Installation automatique des packages manquants"""
        if not missing_packages:
            logger.info("âœ… Aucun package manquant")
            return True
        
        if self.system_state["auto_fix_attempts"] >= self.system_state["max_auto_fix"]:
            logger.error("ğŸ›‘ Nombre maximum de tentatives atteint, intervention manuelle requise")
            return False
        
        self.system_state["auto_fix_attempts"] += 1
        logger.info(f"ğŸ”§ Auto-fix tentative {self.system_state['auto_fix_attempts']}/{self.system_state['max_auto_fix']}")
        
        success_count = 0
        failed_packages = []
        
        for package, import_name in missing_packages:
            logger.info(f"âš™ï¸ Traitement de {package}...")
            
            if self.install_package(package):
                success_count += 1
                time.sleep(2)  # Pause entre installations
            else:
                failed_packages.append(package)
        
        # Rapport
        logger.info(f"ğŸ“Š RÃ©sultat: {success_count}/{len(missing_packages)} packages installÃ©s")
        
        if failed_packages:
            logger.warning(f"âš ï¸ Ã‰checs: {', '.join(failed_packages)}")
            return False
        
        return True
    
    def check_service_running(self, service: Dict) -> bool:
        """VÃ©rifie si un service est en cours d'exÃ©cution"""
        pid_file = Path(service["pid_file"])
        
        if not pid_file.exists():
            return False
        
        try:
            pid = int(pid_file.read_text().strip())
            # VÃ©rifier si le processus existe
            os.kill(pid, 0)
            return True
        except (OSError, ValueError):
            return False
    
    def start_service(self, service: Dict) -> bool:
        """DÃ©marre un service KibaLock"""
        logger.info(f"ğŸš€ DÃ©marrage de {service['name']}...")
        
        script_path = self.script_dir / service["script"]
        
        if not script_path.exists():
            logger.error(f"âŒ Script introuvable: {script_path}")
            return False
        
        try:
            # Lancer en arriÃ¨re-plan
            process = subprocess.Popen(
                [str(self.python_path), str(script_path)],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                start_new_session=True
            )
            
            # Sauvegarder le PID
            Path(service["pid_file"]).write_text(str(process.pid))
            
            # Attendre un peu pour vÃ©rifier que Ã§a dÃ©marre
            time.sleep(3)
            
            if self.check_service_running(service):
                logger.info(f"âœ… {service['name']} dÃ©marrÃ© (PID: {process.pid})")
                return True
            else:
                logger.error(f"âŒ {service['name']} a crashÃ© au dÃ©marrage")
                return False
                
        except Exception as e:
            logger.error(f"ğŸ’¥ Erreur dÃ©marrage {service['name']}: {e}")
            return False
    
    def stop_service(self, service: Dict) -> bool:
        """ArrÃªte un service"""
        logger.info(f"ğŸ›‘ ArrÃªt de {service['name']}...")
        
        pid_file = Path(service["pid_file"])
        
        if not pid_file.exists():
            logger.warning(f"âš ï¸ PID file introuvable pour {service['name']}")
            return True
        
        try:
            pid = int(pid_file.read_text().strip())
            os.kill(pid, 15)  # SIGTERM
            time.sleep(2)
            
            # VÃ©rifier si arrÃªtÃ©
            try:
                os.kill(pid, 0)
                # Toujours en cours, forcer
                os.kill(pid, 9)  # SIGKILL
                logger.warning(f"âš ï¸ Force kill de {service['name']}")
            except OSError:
                pass
            
            pid_file.unlink()
            logger.info(f"âœ… {service['name']} arrÃªtÃ©")
            return True
            
        except Exception as e:
            logger.error(f"ğŸ’¥ Erreur arrÃªt {service['name']}: {e}")
            return False
    
    def restart_all_services(self) -> bool:
        """RedÃ©marre tous les services KibaLock"""
        logger.info("ğŸ”„ RedÃ©marrage de tous les services...")
        
        # ArrÃªter tous les services
        for service in self.services:
            if self.check_service_running(service):
                self.stop_service(service)
        
        time.sleep(2)
        
        # DÃ©marrer tous les services
        success = True
        for service in self.services:
            if not self.start_service(service):
                success = False
        
        return success
    
    def autonomous_maintenance_cycle(self) -> bool:
        """Cycle de maintenance autonome complet"""
        logger.info("=" * 70)
        logger.info("ğŸ¤– CYCLE DE MAINTENANCE AUTONOME")
        logger.info("=" * 70)
        
        self.system_state["last_check"] = datetime.now().isoformat()
        
        # 1. VÃ©rifier les packages
        logger.info("\nğŸ“¦ Phase 1: VÃ©rification des dÃ©pendances")
        missing = self.get_missing_packages()
        
        # 2. Auto-fix si nÃ©cessaire
        if missing:
            logger.info(f"\nğŸ”§ Phase 2: Auto-fix ({len(missing)} packages manquants)")
            if not self.auto_fix_dependencies(missing):
                logger.error("âŒ Auto-fix Ã©chouÃ©")
                return False
            
            # Re-vÃ©rifier aprÃ¨s installation
            missing_after = self.get_missing_packages()
            if missing_after:
                logger.error(f"âŒ Packages toujours manquants: {[p for p, _ in missing_after]}")
                return False
        else:
            logger.info("âœ… Tous les packages sont installÃ©s")
        
        # 3. VÃ©rifier GPU
        logger.info("\nğŸ® Phase 3: VÃ©rification GPU")
        gpu_info = self.check_pytorch_gpu()
        
        # 4. VÃ©rifier les services
        logger.info("\nğŸ” Phase 4: Ã‰tat des services")
        all_running = True
        for service in self.services:
            is_running = self.check_service_running(service)
            self.system_state["services_running"][service["name"]] = is_running
            
            status = "âœ… Running" if is_running else "âŒ Stopped"
            logger.info(f"   {service['name']}: {status}")
            
            if not is_running:
                all_running = False
        
        # 5. RedÃ©marrer si nÃ©cessaire
        if not all_running or missing:
            logger.info("\nğŸ”„ Phase 5: RedÃ©marrage des services")
            if not self.restart_all_services():
                logger.error("âŒ Ã‰chec du redÃ©marrage")
                return False
        
        # Rapport final
        logger.info("\n" + "=" * 70)
        logger.info("âœ… CYCLE DE MAINTENANCE TERMINÃ‰ AVEC SUCCÃˆS")
        logger.info("=" * 70)
        logger.info(f"GPU: {'âœ… Actif' if self.system_state['pytorch_gpu'] else 'âš ï¸ CPU only'}")
        logger.info(f"Packages: {len([p for p in self.system_state['critical_packages'].values() if p])}/{len(self.critical_packages)}")
        logger.info(f"Services: {len([s for s in self.system_state['services_running'].values() if s])}/{len(self.services)}")
        logger.info("=" * 70 + "\n")
        
        return True
    
    def run_continuous_monitoring(self, interval: int = 300):
        """Mode monitoring continu avec cycles automatiques"""
        logger.info("ğŸ”„ DÃ©marrage du monitoring continu...")
        logger.info(f"   Cycle toutes les {interval} secondes")
        
        cycle = 0
        while True:
            cycle += 1
            logger.info(f"\nğŸ” Cycle #{cycle} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            try:
                self.autonomous_maintenance_cycle()
                logger.info(f"ğŸ˜´ Pause de {interval}s jusqu'au prochain cycle...")
                time.sleep(interval)
                
            except KeyboardInterrupt:
                logger.info("\nâš ï¸ Interruption utilisateur, arrÃªt propre...")
                break
            except Exception as e:
                logger.error(f"ğŸ’¥ Erreur dans le cycle: {e}")
                logger.info("â¸ï¸ Pause de 60s avant nouvelle tentative...")
                time.sleep(60)


def main():
    """Point d'entrÃ©e principal"""
    import argparse
    
    parser = argparse.ArgumentParser(description="KibaLock Agent Kernel - SystÃ¨me Autonome Intelligent")
    parser.add_argument("--once", action="store_true", help="ExÃ©cuter un seul cycle de maintenance")
    parser.add_argument("--monitor", action="store_true", help="Mode monitoring continu")
    parser.add_argument("--interval", type=int, default=300, help="Intervalle en secondes (dÃ©faut: 300)")
    parser.add_argument("--install", nargs="+", help="Installer des packages spÃ©cifiques")
    
    args = parser.parse_args()
    
    # BanniÃ¨re
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                               â•‘
â•‘     ğŸ¤– KibaLock Agent Kernel v1.0                            â•‘
â•‘     SystÃ¨me Autonome Intelligent                             â•‘
â•‘                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    agent = KibaLockAgentKernel()
    
    if args.install:
        # Mode installation manuelle
        logger.info(f"ğŸ“¦ Installation manuelle: {args.install}")
        for package in args.install:
            agent.install_package(package)
    
    elif args.monitor:
        # Mode monitoring continu
        agent.run_continuous_monitoring(args.interval)
    
    else:
        # Mode single-shot (dÃ©faut)
        success = agent.autonomous_maintenance_cycle()
        sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
